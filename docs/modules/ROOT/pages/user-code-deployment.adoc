= User Code Deployment
:description: You can deploy your own custom and domain classes to cluster members. With Hazelcast Operator, you can deploy your application code from external buckets and ConfigMap objects in Kubernetes.

WARNING: User Code Deployment is deprecated. Use xref:user-code-namespaces.adoc[User Code Namespaces] instead.

{description}

This topic explains how to configure your code deployments with Hazelcast Operator. 

It also provides example configuration for the use of your code deployments in the configuration of the following:

* <<configuring-an-external-data-store-with-hazelcast-operator,External data stores>>
* <<configuring-an-executor-services-with-the-hazelcast-platform-operator,Executor services>>
* <<configuring-an-entry-processor-with-hazelcast-platform-operator,Entry processors>>

[configuring-user-code-deployment]
== Configure User Code Deployment

User code deployments are configured using the following fields: 

[cols="20%m,80%a"]
|===
|Field|Description

|`clientEnabled`
|Specifies whether to maintain the order of the messages.
If set to `true`, custom code deployment is allowed from Hazelcast clients, otherwise custom code deployment is disallowed.

|`bucketConfig`
|The location and credentials for the bucket used to store external data.
The following attributes must be defined to allow JAR files from an external bucket to be placed under the Java class path:

  - `secretName`: Name of the Secret object that holds the credentials for your cloud provider.
  - `bucketURI`: Full path for the external bucket. For example, `gs://your-bucket/path/to/jars`.

|`configMaps`
|Identifies the files used to apply custom configuration to the Hazelcast cluster. 
The files are placed under the Java class path.

NOTE: The data stored in a ConfigMap cannot exceed 1 MiB. For further information on the restrictions, refer to the link:https://kubernetes.io/docs/concepts/configuration/configmap/#motivation[ConfigMaps,window=_blank] section of the Kubernetes documentation.

|`remoteURLs`
|The URLs from which your code files can be obtained.
Files downloaded from the URLs are placed under the Java class path.

|`triggerSequence`
|Flag to trigger a rolling restart.
When set, a rolling restart downloads the custom code again.

|===

For further information on the fields used to configure user code deployment, see xref:api-ref.adoc#usercodedeploymentconfig[UserCodeDeploymentConfig] in the Hazelcast Operator API Reference.

=== Example Configuration

In this example, we configure the following behavior for user code deployment:

* Download the JAR files from the specified external bucket.
* Place the JARs under the class path of each Hazelcast member.
* Put all files specified in the `ConfigMap` objects under the class path of each Hazelcast member. 

User code deployment can only use external buckets from the following cloud providers:

* AWS S3
* GCP Bucket
* Azure Blob

NOTE: Mounted persistent volumes are not supported.

The configuration required for the supported cloud providers is as follows:

[tabs]
====

AWS::
+
--
[source,yaml,subs="attributes+"]
----
include::ROOT:example$/hazelcast-user-code-deployment-aws.yaml[]
----
--

GCP::
+
--
[source,yaml,subs="attributes+"]
----
include::ROOT:example$/hazelcast-user-code-deployment-gcp.yaml[]
----
--

Azure::
+
--
[source,yaml,subs="attributes+"]
----
include::ROOT:example$/hazelcast-user-code-deployment-azure.yaml[]
----
--
====
<1> The Bucket URI in which to backup data.
<2> Name of the secret with credentials for accessing the Bucket URI.

[configuring-an-external-data-store-with-hazelcast-operator]
== Configure an External Data Store

You can use the `MapLoader` and `MapStore` interfaces in Hazelcast to load map entries from, and save map entries to, an external data store. For further information on these interfaces and their implementation, refer to xref:hazelcast:data-structures:working-with-external-data.adoc[Building a Cache with MapStore,window=_blank] in the Platform documentation.

To use an external data store, you do the following:

. Deploy the `MapLoader` and/or `MapStore` classes to the class path of each Hazelcast member.
. Configure a Map` resource for the `MapLoader` or `MapStore`.

External Data Stores are configured using the following fields in the `Map` resource for a MapStore:

|===
|Field|Description

|`initialMode`
|The initial entry loading mode. 
The default value is `LAZY`, providing asynchronous loading. 
Set to `EAGER` if you want to block map operations until all partitions have been loaded.

|`className`
|Name of the class that you provide to implement the `MapLoader` and/or `MapStore` interface.

|`writeDelaySeconds`
|The length of time in seconds to delay the storing of map entries.

|`writeBatchSize`
|The method used to create batches when writing to the map store. 
When set to `1` (default), Hazelcast writes all map entries to a single batch.
Otherwise the value defines the number of entries to write to a single batch.  

|`writeCoealescing`
|Used only with write-behind mode in a MapStore. 
When set to `true` (default), Hazelcast coalesces updates on a specific key, which means only the last update is applied. 
Set to `false` to store all updates performed on a key to the data store.

|`propertiesSecretName`
|The name of the secret containing the properties used to manage information passed to the MapStore implementation. 
For example, you could provide the URL for your JDBC store, or required authentication credentials.

|===

For further information on the fields used to configure MapStores, see xref:api-ref.adoc#mapstoreconfig[MapStoreConfig] in the Hazelcast Operator API Reference.

=== Example MapStore Configuration

In this example, we configure a MapStore for a Map resource.

The configuration is as follows:

.Example configuration
[source,yaml,subs="attributes+"]
----
include::ROOT:example$/map-map-store.yaml[]
----

[configuring-an-executor-services-with-the-hazelcast-platform-operator]
== Configure Executor Services

The Hazelcast executor service, `IExecutorService`, executes tasks asynchronously and manages other useful tasks, such as progress tracking for asynchronous tasks.

To use the executor service, do the following:

. Deploy your `Callable` or `Runnable` classes to the class path of each Hazelcast member.
. Configure a Hazelcast custom resource for the `Callable` or `Runnable` interface.

The executor service has the following variants:

- Executor Service
- Durable Executor Service
- Scheduled Executor Service

Each executor service variant is configured using the following fields:  

[tabs]
====
Executor Service::
+
--
For further information, see xref:api-ref.adoc#executorserviceconfiguration[ExecutorServiceConfiguration] in the Hazelcast Operator API Reference.

|===
|Field|Description

|`name`
|The name of the executor service.

|`poolSize`
|The number of executor threads for each member.

|`queueCapacity`
|The capacity of the executor task queue.

|===
--

Durable Executor Service::
+
--
For further information, see xref:api-ref.adoc#durableexecutorserviceconfiguration[DurableExecutorServiceConfiguration] in the Hazelcast Operator API Reference.

|===
|Field|Description

|`name`
|The name of the executor service.

|`poolSize`
|The number of executor threads for each member.

|`durability`
|The number of backups in the cluster for the submitted task.

|`capacity`
|The capacity of the executor task for each partition.

|===
--


Scheduled Executor Service::
+
--
For further information, see xref:api-ref.adoc#scheduledexecutorserviceconfiguration[ScheduledExecutorServiceConfiguration] in the Hazelcast Operator API Reference.

|===
|Field|Description

|`name`
|The name of the executor service.

|`poolSize`
|The number of executor threads for each member.

|`durability`
|The number of backups in the cluster for the submitted task.

|`capacity`
|The cCapacity of the executor task for each partition.

|`capacityPolicy`
|The active policy for the capacity setting.

|===
--

====

Example implementations are provided below.

For further information on implementing and executing executor services, refer to xref:hazelcast:computing:executor-service.adoc[Java Executor Service,window=_blank] in the Platform documentation.

=== Example Executor Services

In the following examples, we configure each executor service variant in a Hazelcast custom resource:

[tabs]
====
Executor Service::
+
--
[source,yaml,subs="attributes+"]
----
include::ROOT:example$/hazelcast-executor-service.yaml[]
----
--

Durable Executor Service::
+
--
[source,yaml,subs="attributes+"]
----
include::ROOT:example$/hazelcast-durable-executor-service.yaml[]
----
--


Scheduled Executor Service::
+
--
[source,yaml,subs="attributes+"]
----
include::ROOT:example$/hazelcast-scheduled-executor-service.yaml[]
----
--

====

[configuring-an-entry-processor-with-hazelcast-platform-operator]
== Configuring an Entry Processor with Hazelcast Platform Operator

An entry processor executes your code on a map entry atomically. 

To implement the `EntryProcessor` interface, you can deploy an `EntryProcessor` class from Hazelcast Operator to the class path of a Hazelcast member. 

For further information on using an entry processor, refer to xref:hazelcast:computing:entry-processor.adoc[Entry Processor,window=_blank] in the Platform documentation.
